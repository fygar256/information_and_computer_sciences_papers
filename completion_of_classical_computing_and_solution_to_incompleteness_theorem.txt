# completion_of_classical_computing_and_solution_to_incompleteness_theorem


The Completion of Classical Computer Processing

Since all operations in classical computers ultimately boil down to converting 1s and 0s, cutting-edge research appears to be developing a General Code Converter. 

The function of classical computers is merely converting 1s and 0s. From this perspective, 

the General Code Converter represents the ultimate code conversion for information expressible solely through “1s and 0s,” transcending all codes and instructions. 

Conversion to other architectures or languages is, in a sense, a form of “translation,” fundamentally organizing data flow and operations. 

How this converter handles conversion rules likely involves adaptation files (or sets thereof) for each specific case. 

This approach seems to create a flexible system capable of adding new conversion rules as needed. 

While individual files offer significant convenience for code reuse and extension, they also seem capable of handling an enormous number of conversion patterns. 

On the other hand, since the number of matching files (sets) becomes vast, individual cases must be abstracted. 

Through abstraction, individual cases are transformed into common patterns, enabling the common elements to be treated as a single rule. 

This abstraction is akin to extracting commonalities in data structures to form patterns, or using a conceptually describable language. 

Furthermore, as abstraction progresses across hierarchical levels, the General Code Converter could theoretically function as a universal “conversion engine” capable of handling any architecture or language.

Music, sound, images, video, words, symbols, mathematical systems, academic theories, resistance values, current values, physical theories, social phenomena, celestial movements, natural phenomena,

quantitatively describable information, smells, sensations, emotions, instincts—all seem quantifiable. 

Ideally, it should process everything that can be coded. Processing everything is impossible, but limiting the scope could make it feasible. 

A Turing machine has an infinitely long tape and infinite processing time. Human developers are necessary. 

Ultimately, humans feed the computer, but a terrifying device capable of replacing humans might emerge. 

Devices connecting to the brain already exist and are under further research. Biological computers... 

Scary, scary. There are ethical issues. In terms of intelligence, computers will likely surpass individuals eventually, 

but computers are ultimately machines (tools) and must not become masters of humans. 

Computers lack consciousness or life (though consciousness and life might be the same thing—we don't know yet), while humans possess imagination and creativity (though computers may acquire these too).

If they compete, it seems like an endless meta-meta competition between computers and humans would ensue. 

Tools should be used. Humans must not become tools.

As AI advances, it might eventually handle automated testing and debugging of massive and/or complex programs.

Will humans become design specialists?!

Also,

#### Solving the Incompleteness Theorem

Does applying the incompleteness theorem to a computer not prove its own completeness by itself require human evaluation? 

Since von Neumann computers are inherently finite and can only handle infinity formally or theoretically, please read the paragraph below assuming that they can theoretically handle infinity. 

Classical computers have finite memory and time, but they can theoretically create infinity—in fact, since the Turing machine is the prototype, they are theoretically infinite. 

Extremely simple examples of infinity include while 1 {}, a value added infinitely in an infinite loop, and an ideal, but never-ending, input in real time.

To solve the incompleteness theorem, all you need is two axiom systems: one for processing and one for evaluation. 

Systems that are not consistently infinite (finite systems), extremely simple systems, or systems that are not consistent and recursively enumerable are not affected by the incompleteness theorem.

Therefore, the evaluation system can be finite, extremely simple, or consistent and not recursively enumerable. Without infinity, errors can be detected. 

That's what we call a simple system. This solves the incompleteness theorem. I haven't been able to logically prove it, but with another axiom system, we can evaluate the self-contradiction. 

Russell simplified it. That's enough. Ultimately, automated debuggers don't need human evaluation (this is the current hypothesis that fully automated debugging by computers is possible).

However, someone devilishly clever like Kurt Gödel might come along and invent a new theory, making the problem unsolvable. 

If the second axiom system is complete and doesn't satisfy any of the three conditions listed above, there's a risk that it will be overturned by the incompleteness theorem. 

Something's wrong. I thought the incompleteness theorem was solvable. The logical proof of the solution to the incompleteness theorem has already been achieved and is taught at universities. 

Thank you, logicians, for letting me know.

ChatGPT Output

“Please explain the negation of the incompleteness theorem.”

"3. Proofs from Outside the Axiom System

The incompleteness theorem demonstrates that “there exist propositions that cannot be proven within a given axiomatic system.” 

However, introducing another system (such as a higher-level system) may allow one to prove consistency. 

Yet, since this is not a “proof from within,” it cannot be called a ‘refutation’ of the incompleteness theorem."

It can't be called a “refutation,” but can it be called a solution?

April Fools' Day

This verse sings of lies

Kotaro

#### Comment

In another 20 years, personal quantum computers will become practical, and children will play with quantum computers too. 

Classical computers and quantum computers have different strengths, so we'll likely still need both for a while.

My writing might be a bit off.

I got too abstract. My conversation partner for this article was ChatGPT.

Sorry for sounding so high and mighty.

Translated with DeepL.com (free version)
